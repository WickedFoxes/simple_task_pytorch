seed: 42
device: "cuda"

dataset:
  name: "imdb"
  root: "./data/imdb"
  pretrained_tokenizer_name: "google-bert/bert-base-cased"
  num_workers: 8
  batch_size: 32
  pin_memory: true
  max_len: 400

model:
  name: "bert_classifier"
  num_classes: 2
  pad_idx: 0 # tokenizer의 pad_idx
  pooling: "cls" # cls or mean
  dropout: 0.1
  pretrained_model_name: "google-bert/bert-base-cased"

optimizer:
  name: "adamw"
  lr: 3e-5
  weight_decay: 0.01

scheduler:
  name: "cosine"
  max_epochs: 5 # trainer의 epochs와 동일하게 설정
  min_lr: 1e-6
  warmup_epochs: 1

loss:
  name: "cross_entropy"

logger:
  name: "simple"

trainer:
  name : "classifier_trainer"
  epochs: 5
  grad_clip: 1.0
  amp: true             # mixed precision
  val_interval: 1       # 에폭 단위 검증
  save_best: true

checkpoint_saver:
  save_dir: "checkpoints/bert_classifier"
  save_best: true
  save_last: false

early_stop:
  patience: 5