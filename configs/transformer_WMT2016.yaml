seed: 42
device: "cuda"

dataset:
  name: "wmt16_de_en"
  root: "/content/drive/MyDrive/Colab_sample_data/wmt16_de_en"
  num_workers: 4
  batch_size: 32
  pin_memory: true
  tokenizer_dir: "/content/drive/MyDrive/Colab_sample_data/wmt16_de_en/spm37k.model"
  pad_idx: 3
  bos_idx: 1
  max_train_data_len: 320
  max_eval_data_len: 32


model:
  name: "transformer_tl"
  vocab_size: 37000 # tokenizer의 vocab_size
  pad_id: 3 # tokenizer의 pad_idx
  embed_dim: 512
  num_heads: 8
  num_encoder_layers: 6
  num_decoder_layers: 6
  dropout_p: 0.1
  feedforward_dim: 2048

optimizer:
  name: "adamw"
  lr: 3e-4
  weight_decay: 0.01

scheduler:
  name: "cosine_schedule_with_warmup"
  num_cycles: 0.5
  # num_warmup_steps: 35538
  # num_training_steps: 710760
  num_warmup_steps: 5
  num_training_steps: 50
  
loss:
  name: "label_smoothing"
  label_smoothing: 0.1
  ignore_index: 3 # tokenizer의 pad_idx

logger:
  name: "simple"

trainer:
  name : "translate_trainer"
  epochs: 5
  grad_clip: 1.0
  amp: true             # mixed precision
  val_interval: 1       # 에폭 단위 검증
  save_best: true
  log_step: 2
  # log_step: 3500

checkpoint_saver:
  save_dir: "/content/drive/MyDrive/Colab_sample_checkpoints/transformer_tl/wmt16_de_en"
  save_best: true
  save_last: true
  mode: "min"